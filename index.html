<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="author" content="Xianggang Yu">
  <meta name="description" content="Xianggang Yu's Homepage"
  <meta name="keywords" content="Xianggang Yu,余湘港,Homepage,主页, PhD, Computer Vision, AIGC, Digital human, CUHK-SZ, 3D reconstruction, Neural rendering>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Xianggang Yu (余湘港)'s Homepage</title>
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xianggang Yu &nbsp; &nbsp;余湘港</name>
              </p>
              <p style="text-align:center">
                <a href="mailto:xianggangyu@link.cuhk.edu.cn">Email</a>
                &nbsp; &nbsp;&nbsp;&nbsp; <a href="https://scholar.google.com.hk/citations?hl=en&user=lR2q0AkAAAAJ">Google Scholar</a> &nbsp; &nbsp;&nbsp;&nbsp;<a href="https://github.com/Larry-u">Github</a>
              </p>

              <div class="w3-content" style="text-align: justify">
              <p>I am a PhD student at the Future Network of Intelligence Institute (<a href="https://fnii.cuhk.edu.cn/">FNii</a>) 
                and the School of Science and Engineering (<a href="https://fnii.cuhk.edu.cn/">SSE</a>) 
                at The Chinese University of Hong Kong, Shenzhen (<a href="https://www.cuhk.edu.cn/zh-hans">CUHK-Shenzhen</a>).
                I am co-supervised by <a href="https://sse.cuhk.edu.cn/en">Prof. Shuguang Cui</a> and <a href="https://sse.cuhk.edu.cn/en">Prof. Xiaoguang Han</a>.
                I obtained my bachelor degree in Computer Science and Engineering from CUHK-Shenzhen in 2019.
                <br>
                <br>
                My research interests lie on deep learning based image&video generation, neural rendring, digital avatar reconstruction, and AIGC.
              </p>
              </div>
            </td>
            <td style="padding:10% 3% 3% 3%;width:40%;max-width:40%">
              <a href="images/portrait.jpg"><img style="width:70%;max-width:120%" alt="profile photo" src="images/portrait.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        

        <!-- news -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
              2023-02: 	One paper about a large-scale dataset (<a href="https://gaplab.cuhk.edu.cn/projects/MVImgNet/">MVImgNet</a>) is accepted by CVPR 2023, the dataset will be released soon.<br>
            </p>
          </td>
        </tr>
      </tbody></table>





      <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:20px;padding-left:20px;padding-bottom:5px"><tbody>
        <tr> <td>
                <heading>Publications</heading>  (<strong><sup>#</sup></strong> corresponding author, <strong>*</strong> equal contribution)
                <!--<heading>Publications</heading>  (<strong><sup>&dagger;</sup></strong> corresponding author, <strong>*</strong> equal contribution)-->
          </td> </tr>
      </tbody> </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <!-- MVImgNet -->
          <tr></tr>
          <td style="padding:10px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='./images/MVImgNet.png' style="height:100%;width:140%; position: absolute;top: -0%">
            </div>
          </td>
          
          <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle>MVImgNet: A Large-scale Dataset of Multi-view Images</papertitle>
            <br>
            <strong>Xianggang Yu<sup>*</sup></strong>, <a href="https://mutianxu.github.io/">Mutian Xu<sup>*</sup></a>, Yidan
            Zhang<sup>*</sup>, Haolin Liu<sup>*</sup>,
            Chongjie Ye<sup>*</sup>,<br> Yushuang Wu, Zizheng Yan, Chenming Zhu, Zhangyang Xiong, Tianyou Liang, <br>
            <a href="https://guanyingc.github.io/">Guanying Chen</a>,
            <a href="https://sse.cuhk.edu.cn/en">Shuguang Cui</a>,
            <a href="https://gaplab.cuhk.edu.cn/">Xiaoguang Han<sup>#</sup></a>
            <br>
            <em>2023 IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2023
            <br>
            <a href="https://gaplab.cuhk.edu.cn/projects/MVImgNet/">[Project]</a>
            <a href="">[PDF]</a>
            <a href="">[BibTeX]</a>
            <a href="">[Code]</a>
            <br>
            <div class="w3-content" style="text-align: justify">
              <p>
              </p>
            </div>
          </td>
          </tr>

        <!-- PVSeRF -->
        <tr></tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='./images/PVSeRF_teaser.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
          </div>
        </td>
        
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>PVSeRF: Joint Pixel-, Voxel- and Surface-Aligned Radiance Field for Single-Image Novel View Synthesis</papertitle>
          <br>
          <strong>Xianggang Yu</strong>, <a href="https://tangjiapeng.github.io/">Jiapeng Tang</a>,
          <a href="http://yipengqin.github.io/">Yipeng Qin</a>, Chenghong Li, <a href="https://linchaobao.github.io/">Linchao Bao</a>,
          <a href="https://gaplab.cuhk.edu.cn/">Xiaoguang Han<sup>#</sup></a>,
          <a href="https://sse.cuhk.edu.cn/en">Shuguang Cui</a>
          <br>
          <em>2022 ACM International Conference on Multimedia</em>, ACMMM 2022
          <br>
          <a href="https://arxiv.org/abs/2202.04879">[PDF]</a>
          <a href="./bib/pvserf.txt">[BibTeX]</a>
          <a href="">[Code]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
            <p>
            </p>
          </div>
        </td>
        </tr>

        
        <!-- Pix DA -->
        <tr></tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='./images/PixIntraDA.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
          </div>
        </td>
        
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Pixel-level intra-domain adaptation for semantic segmentation</papertitle>
          <br>
          Zizheng Yan, <strong>Xianggang Yu</strong>, <a href="http://yipengqin.github.io/">Yipeng Qin</a>, Yushuang Wu,
          <a href="https://gaplab.cuhk.edu.cn/">Xiaoguang Han<sup>#</sup></a>,
          <a href="https://sse.cuhk.edu.cn/en">Shuguang Cui</a>
          <br>
          <em>2021 ACM International Conference on Multimedia</em>, ACMMM 2021
          <br>
          <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475174">[PDF]</a>
          <a href="./bib/pixintrada.txt">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
            <p>
            </p>
          </div>
        </td>
        </tr>


        <!-- JAFPro -->
        <tr></tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='./images/JAFPro.png' style="height:80%;width:140%; position: absolute;top: 5%">
          </div>
        </td>
        
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>JAFPro: Joint Appearance Fusion and Propagation for Human Video Motion Transfer from Multiple Reference Images</papertitle>
          <br>
          <strong>Xianggang Yu<sup>*</sup></strong>, Haolin Liu<sup>*</sup>, <a href="https://gaplab.cuhk.edu.cn/">Xiaoguang Han<sup>#</sup></a>,
          <a href="https://sse.cuhk.edu.cn/faculty/lizhen">Zhen Li</a>,
          <a href="https://engineering.tamu.edu/electrical/profiles/zxiong.html">Zixiang Xiong</a>,
          <a href="https://sse.cuhk.edu.cn/en">Shuguang Cui</a>
          <br>
          <em>2020 ACM International Conference on Multimedia</em>, ACMMM 2020
          <br>
          <a href="https://dl.acm.org/doi/10.1145/3394171.3414001">[PDF]</a>
          <a href="./bib/jafpro.txt">[BibTeX]</a>
          <a href="https://github.com/Larry-u/JAFPro">[Code]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
            <p>
            </p>
          </div>
        </td>
        </tr>


        <!-- PG -->
        <tr></tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='./images/PG2020.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
          </div>
        </td>
        
        <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>A deep learning based interactive sketching system for fashion images design</papertitle>
          <br>
          Yao Li, <strong>Xianggang Yu</strong>, <a href="https://gaplab.cuhk.edu.cn/">Xiaoguang Han</a>, Nianjuan Jiang, Kui Jia, Jiangbo Lu
          <br>
          <em>2020 Pacific Graphics</em>, PG 2020
          <br>
          <a href="https://arxiv.org/abs/2010.04413">[PDF]</a>
          <a href="./bib/pg2020.txt">[BibTeX]</a>
          <br>
          <div class="w3-content" style="text-align: justify">
            <p>
            </p>
          </div>
        </td>
        </tr>

        <!-- <tr></tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
                <div class="one" >
                    <img src='./2022/ETHSeg/img_comparison.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>ETHSeg: An Amodel Instance Segmentation Network and a Real-world Dataset for X-Ray Waste Inspection</papertitle>
                <br>
                <strong>Xianggang Yu</strong>, Zhangyang Xiong, Xuhao Wang, KenKun Liu, <a href="https://guanyingc.github.io/">Guanying Chen</a>, <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han<sup>#</sup></a>, Shuguang Cui
                <br>
                <em>2022 IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2022, 
                <br>
                <a href="./2022/ETHSeg/">[Project]</a>
                <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Qiu_ETHSeg_An_Amodel_Instance_Segmentation_Network_and_a_Real-World_Dataset_CVPR_2022_paper.pdf">[PDF]</a>
                <a href="https://drive.google.com/file/d/1maV_P5vFahWvOi3a7EHdhMpaI9fV8Ed9/view">[Dataset]</a>
				        <a href="images/fenerf.txt">[BibTeX]</a>
                <br>
                <div class="w3-content" style="text-align: justify">
                <p>
                </p>
                </div>
            </td>
        </tr>


        <tr></tr>
        <td style="padding:10px;width:25%;vertical-align:middle">
              <div class="one" >
                <video playsinline autoplay loop preload muted style="width:140%; position: absolute;top: -0%">
                            <source src='./ReEF/ReEF.mp4'>
                </video>
            </div>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <papertitle> Registering Explicit to Implicit:
              Towards High-Fidelity Garment mesh Reconstruction from Single Images </papertitle>
            <br>
            <a herf="https://people.mpi-inf.mpg.de/~hezhu/">Heming Zhu</a>, <strong>Xianggang Yu</strong>, Yuda Qiu, <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han<sup>#</sup></a>
            <br>
            <em>2022 IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2022, 
            <br>
            <a href="https://kv2000.github.io/2022/03/28/reef/">[Project]</a>
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zhu_Registering_Explicit_to_Implicit_Towards_High-Fidelity_Garment_Mesh_Reconstruction_From_CVPR_2022_paper.pdf">[PDF]</a>
            <a href="./ReEF/ReEF.txt">[BibTeX]</a>
            <a href="https://kv2000.github.io/2022/03/28/reef/">[Code]</a>
            <br>
            <div class="w3-content" style="text-align: justify">
            <p> 
            </p>
            </div>
        </td>
    </tr> -->


    <!-- cvpr2021 -->
    <!-- <tr></tr>
    <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one" >
            <div class="one" >
              <img src='./2021/3DCariShop/paper-teaser.jpg' style="height:100%;width:140%; position: absolute;top: -0%">
            </div>
            </video>
        </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle> 3DCaricShop: A Dataset and A Baseline Method for Single-view 3D Caricature Face Reconstruction </papertitle>
        <br>
        Yuda Qiu, Xiaojie Xu, <strong>Xianggang Yu</strong>, Yan Pan, Yushuang Wu, Weikai Chen, <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han<sup>#</sup></a>
        <br>
        <em>2021 IEEE Conference on Computer Vision and Pattern Recognition</em>, CVPR 2021, 
        <br>
        <a href="./2021/3DCariShop/">[Project]</a>
        <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Qiu_3DCaricShop_A_Dataset_and_a_Baseline_Method_for_Single-View_3D_CVPR_2021_paper.pdf">[PDF]</a>
        <a href="https://github.com/qiuyuda/3DCaricShop">[Dataset]</a>
        <a href="./2021/3DCariShop/3d_carishop.txt">[BibTeX]</a>
        <a href="https://github.com/qiuyuda/3DCaricShop">[Code]</a>
        <br>
        <div class="w3-content" style="text-align: justify">
        <p> 
        </p>
        </div>
    </td> -->
    <!-- eccv2022 -->
    <!-- <tr></tr>
    <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one" >
            <div class="one" >
              <img src='./2020/OPEC-Net/media/pipeline.png' style="height:100%;width:140%; position: absolute;top: -0%">
            </div>
            </video>
        </div>
    </td> -->
    <!-- <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle> Peeking into Occluded Joints: A Novel Framework for Crowd Pose Estimation </papertitle>
        <br>
        <strong>Xianggang Yu</strong>, Yanran Li, Guanbin Li ,Xiaojun Wu, Zixiang Xiong,
        <a href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han</a><sup>#</sup>, Shuguang Cui
        <br>
        <em>2020 European Conference on Computer Vision</em>, ECCV 2020, 
        <br>
        <a href="./2020/OPEC-Net/">[Project]</a>
        <a href="https://arxiv.org/pdf/2003.10506.pdf">[PDF]</a>
        <a href="./2020/OPEC-Net/opec.txt">[BibTeX]</a>
        <a href="https://github.com/lingtengqiu/OPEC-Net">[Code]</a>
        <a href="https://github.com/lingtengqiu/OPEC-Net" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/lingtengqiu/OPEC-Net?style=social"></a>
        <br>
        <div class="w3-content" style="text-align: justify">
        <p> 
        </p>
        </div>
    </td> -->



    <!-- project -->

    



    <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Projects</heading>
      </td>
    </tr>
  </tbody></table>

  <table style="width:100%;border:0px; border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> -->

    <!-- open-pifuhd -->
    <!-- <tr></tr>
    <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one" >
            <div class="one" >
              <img src='./project/open-pifuhd.png' style="height:60%;width:140%; position: absolute;top: 5%">
            </div>
            </video>
        </div>
    </td>
    <td style="padding:20px ;width:75%;vertical-align:middle">
        <papertitle> Open-PIFuhd</papertitle><br>
        This is an implementation of PIFuhd based on PyTorch, including rendering image normal map, training both coarse-PIFu 
        and fine-PIFu.<br>
        <a href="https://github.com/lingtengqiu/Open-PIFuhd">[Code]</a>
        <a href="https://github.com/lingtengqiu/Open-PIFuhd" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/lingtengqiu/Open-PIFuhd?style=social"></a>
        <br>
        <br>
        <br>
    </td> -->

    <!-- deeperlab -->
    <!-- <tr></tr>
    <td style="padding:10px;width:25%;vertical-align:middle">
          <div class="one" >
            <div class="one" >
              <img src='./project/DeeperLab.png' style="height:60%;width:140%; position: absolute;top: 5%">
            </div>
            </video>
        </div>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle> DeeperLab</papertitle><br>
        This project aims at providing a fast, modular reference implementation for semantic segmentation models using PyTorch.<br>
        <a href="https://github.com/lingtengqiu/Deeperlab-pytorch">[Code]</a>
        <a href="https://github.com/lingtengqiu/Deeperlab-pytorch" target="_blank"><img class="imgbadge" src="https://img.shields.io/github/stars/lingtengqiu/Deeperlab-pytorch?style=social"></a>
        <br>
        <br>
        <br>
    </td></tr>
  </table> -->


      <!-- <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:20px;padding-left:20px;padding-bottom:5px"><tbody>
      <tr> <td>
          <heading>Current Collaborators</heading>
        </td> </tr>
    </tbody> </table>
  <table width="100%" align="center" border="0" cellspacing="0" style="padding-top:00px;padding-left:20px;padding-bottom:5px"><tbody>
      <tr> <td>
          • <a href="https://guanyingc.github.io/">Guanying Chen</a>, Research Assistant Professor in CUHK-SZ</br>
        </td> </tr>
    </tbody> -->



    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr> <td style="padding:0px"> <br>
         <p>                   The website template was adapted from <a href="https://guanyingc.github.io/">Guanying Chen</a>.</p>
        </td> </tr>
    </tbody> </table>
   

    
  </table>



</body>

</html>
